{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"5a71cf88-efe3-44c5-ac7d-026e795a61e9","_cell_guid":"ec50839e-a12e-4d57-af07-1e879a80fca0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:18:42.395912Z","iopub.execute_input":"2023-10-06T13:18:42.396256Z","iopub.status.idle":"2023-10-06T13:18:42.697228Z","shell.execute_reply.started":"2023-10-06T13:18:42.396233Z","shell.execute_reply":"2023-10-06T13:18:42.696355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\ndf.head()","metadata":{"_uuid":"94264443-969b-48fb-adbe-8d4d9bb852b9","_cell_guid":"09c36789-4959-4031-98b6-da228ee60a34","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:18:42.699009Z","iopub.execute_input":"2023-10-06T13:18:42.699776Z","iopub.status.idle":"2023-10-06T13:18:42.738774Z","shell.execute_reply.started":"2023-10-06T13:18:42.699745Z","shell.execute_reply":"2023-10-06T13:18:42.737896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers[torch]","metadata":{"_uuid":"8c26acc5-99f1-40ff-9d29-042d4cf04cbd","_cell_guid":"48482b47-94cd-4c7b-9ced-8766253224d5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:18:42.740068Z","iopub.execute_input":"2023-10-06T13:18:42.740654Z","iopub.status.idle":"2023-10-06T13:19:18.612451Z","shell.execute_reply.started":"2023-10-06T13:18:42.740624Z","shell.execute_reply":"2023-10-06T13:19:18.611406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, Trainer, TrainingArguments, BertForMultipleChoice, BertConfig\n\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split","metadata":{"_uuid":"2c479463-fa71-418a-b9a5-6b1c4cadee28","_cell_guid":"540e74c5-e8d8-423e-bee5-932f11397bb7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:18.615564Z","iopub.execute_input":"2023-10-06T13:19:18.615916Z","iopub.status.idle":"2023-10-06T13:19:34.076655Z","shell.execute_reply.started":"2023-10-06T13:19:18.615879Z","shell.execute_reply":"2023-10-06T13:19:34.075778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom typing import Optional, Union\nimport torch.nn as nn","metadata":{"_uuid":"001b3bf0-d80d-419d-8105-46083db240f7","_cell_guid":"4275c457-4eb5-4825-8690-3598c1e04b64","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.078056Z","iopub.execute_input":"2023-10-06T13:19:34.078942Z","iopub.status.idle":"2023-10-06T13:19:34.083863Z","shell.execute_reply.started":"2023-10-06T13:19:34.078908Z","shell.execute_reply":"2023-10-06T13:19:34.082941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"daef7a86-f074-44d3-a2aa-17d51e1af6c0","_cell_guid":"25d8038b-f4e5-44ce-9e3b-f2db6c500105","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.085359Z","iopub.execute_input":"2023-10-06T13:19:34.085693Z","iopub.status.idle":"2023-10-06T13:19:34.096600Z","shell.execute_reply.started":"2023-10-06T13:19:34.085665Z","shell.execute_reply":"2023-10-06T13:19:34.095787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"0402245b-40c4-471e-88f3-4f1d69f52b02","_cell_guid":"fd1c1662-f81c-466f-b0c8-86996000166f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.097845Z","iopub.execute_input":"2023-10-06T13:19:34.098675Z","iopub.status.idle":"2023-10-06T13:19:34.170974Z","shell.execute_reply.started":"2023-10-06T13:19:34.098646Z","shell.execute_reply":"2023-10-06T13:19:34.169962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"_uuid":"cc30b18f-58fa-473d-91dd-a4e9db8b4d99","_cell_guid":"6ae812a3-6b7c-43d8-836d-2f013fd5c69f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.172359Z","iopub.execute_input":"2023-10-06T13:19:34.172683Z","iopub.status.idle":"2023-10-06T13:19:34.184314Z","shell.execute_reply.started":"2023-10-06T13:19:34.172653Z","shell.execute_reply":"2023-10-06T13:19:34.183513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = '/kaggle/input/huggingface-bert/bert-large-uncased'\ntokenizer = AutoTokenizer.from_pretrained(model_dir)","metadata":{"_uuid":"43708899-aedf-4bf4-a133-e71f082d5913","_cell_guid":"8938e083-30c8-42c8-8ef7-2cf267f58008","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.185673Z","iopub.execute_input":"2023-10-06T13:19:34.186319Z","iopub.status.idle":"2023-10-06T13:19:34.272054Z","shell.execute_reply.started":"2023-10-06T13:19:34.186289Z","shell.execute_reply":"2023-10-06T13:19:34.271260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preprocesing the data \ndef preprocess_data(df):\n    tokenized_data = []\n\n    for index, row in df.iterrows():\n        question = row['prompt']\n        options = {\n            'A': row['A'],\n            'B': row['B'],\n            'C': row['C'],\n            'D': row['D'],\n            'E': row['E']\n        }\n\n        input_ids_list = []\n        attention_mask_list = []\n\n        for key, option in options.items():\n            encoded_data = tokenizer(\n                question,\n                option,\n                truncation=True,\n                padding='max_length',\n                max_length=128,\n                return_tensors='pt',\n            )\n\n            input_ids_list.append(encoded_data['input_ids'])\n            attention_mask_list.append(encoded_data['attention_mask'])\n\n        label = ord(row['answer']) - ord('A')  # Преобразование буквы ответа в числовую метку (0-4)\n\n        tokenized_example = {\n            'input_ids': input_ids_list,\n            'attention_mask': attention_mask_list,\n            'label': label\n        }\n\n        tokenized_data.append(tokenized_example)\n\n    tokenized_df = pd.DataFrame(tokenized_data)\n    return tokenized_df","metadata":{"_uuid":"178a77b7-6837-4a0d-bea7-a49be1bbc95c","_cell_guid":"1a266e74-711d-4d21-a4a0-4f5bdc9dba6b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.275604Z","iopub.execute_input":"2023-10-06T13:19:34.275839Z","iopub.status.idle":"2023-10-06T13:19:34.281909Z","shell.execute_reply.started":"2023-10-06T13:19:34.275819Z","shell.execute_reply":"2023-10-06T13:19:34.281073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_df = preprocess_data(df)","metadata":{"_uuid":"2c52f9b8-d28c-414f-aef8-1a816bc5d3a3","_cell_guid":"52dde8bf-4828-4ad1-a194-4710c023f3fe","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.283128Z","iopub.execute_input":"2023-10-06T13:19:34.283731Z","iopub.status.idle":"2023-10-06T13:19:34.688843Z","shell.execute_reply.started":"2023-10-06T13:19:34.283702Z","shell.execute_reply":"2023-10-06T13:19:34.688030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultipleChoiceDataset(Dataset):\n    def __init__(self, dataframe):\n        self.data = dataframe\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        input_ids = self.data.iloc[idx]['input_ids']\n        attention_mask = self.data.iloc[idx]['attention_mask']\n        label = self.data.iloc[idx]['label']\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': label\n        }","metadata":{"_uuid":"407466a0-ae29-4056-a034-4f9ed43da984","_cell_guid":"f5877832-c808-45af-bcc3-89daab0e7afa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.690126Z","iopub.execute_input":"2023-10-06T13:19:34.690612Z","iopub.status.idle":"2023-10-06T13:19:34.696574Z","shell.execute_reply.started":"2023-10-06T13:19:34.690582Z","shell.execute_reply":"2023-10-06T13:19:34.695793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = MultipleChoiceDataset(tokenized_df)","metadata":{"_uuid":"90fc00e4-4e1c-4db8-b5e8-cfbe5c30d516","_cell_guid":"21e4edd4-85fa-4826-90d3-8db5b2afc113","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.698066Z","iopub.execute_input":"2023-10-06T13:19:34.698365Z","iopub.status.idle":"2023-10-06T13:19:34.706235Z","shell.execute_reply.started":"2023-10-06T13:19:34.698339Z","shell.execute_reply":"2023-10-06T13:19:34.705334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size_train = 5\nbatch_size_val = 5\n\nvalidation_ratio = 0.1\n\nnum_validation = int(validation_ratio * len(dataset))\nnum_train = len(dataset) - num_validation\n\ntrain_dataset, val_dataset = random_split(dataset, [num_train, num_validation])\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False)","metadata":{"_uuid":"5f5af10e-a21c-486d-9e3b-f90c4fc11a3f","_cell_guid":"d8f12458-7cc6-4c08-bdc4-114670c8d6d1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:19:34.707665Z","iopub.execute_input":"2023-10-06T13:19:34.708730Z","iopub.status.idle":"2023-10-06T13:19:34.732931Z","shell.execute_reply.started":"2023-10-06T13:19:34.708648Z","shell.execute_reply":"2023-10-06T13:19:34.732174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the model\nmodel = BertForMultipleChoice.from_pretrained(model_dir, num_labels=df['answer'].nunique())","metadata":{"_uuid":"86f3d2e9-82e6-4316-94d8-4da50bcadbfe","_cell_guid":"417582ad-361f-481d-b758-fe47c9a6b367","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:21:16.674253Z","iopub.execute_input":"2023-10-06T13:21:16.674732Z","iopub.status.idle":"2023-10-06T13:21:22.813720Z","shell.execute_reply.started":"2023-10-06T13:21:16.674691Z","shell.execute_reply":"2023-10-06T13:21:22.812858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a list to store the even layers\n#even_layers = []\n\n# Specify the even layers you want to keep (e.g., every second layer)\n#for i, layer in enumerate(original_bert_model.bert.encoder.layer):\n#    if i % 2 == 0:\n#        even_layers.append(layer)\n\n# Create a new BERT model with even layers\n#config = BertConfig.from_pretrained(model_dir)\n#config.num_hidden_layers = len(even_layers)  # Update the number of layers\n#model = BertForMultipleChoice(config=config)\n#model.bert.encoder.layer = nn.ModuleList(even_layers)  # Set the even layers","metadata":{"execution":{"iopub.status.busy":"2023-10-06T13:21:24.350390Z","iopub.execute_input":"2023-10-06T13:21:24.351028Z","iopub.status.idle":"2023-10-06T13:21:24.355238Z","shell.execute_reply.started":"2023-10-06T13:21:24.350997Z","shell.execute_reply":"2023-10-06T13:21:24.354246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a list to store the odd layers\n#odd_layers = []\n\n# Specify the odd layers you want to keep (e.g., every second layer starting from the first layer)\n#for i, layer in enumerate(original_bert_model.bert.encoder.layer):\n#    if i % 2 == 1:\n#        odd_layers.append(layer)\n\n# Create a new BERT model with odd layers\n#config = BertConfig.from_pretrained(model_dir)\n#config.num_hidden_layers = len(odd_layers)  # Update the number of layers\n#model = BertForMultipleChoice(config=config)\n#model.bert.encoder.layer = nn.ModuleList(odd_layers)  # Set the odd layers","metadata":{"execution":{"iopub.status.busy":"2023-10-06T13:21:25.526927Z","iopub.execute_input":"2023-10-06T13:21:25.527220Z","iopub.status.idle":"2023-10-06T13:21:25.531448Z","shell.execute_reply.started":"2023-10-06T13:21:25.527196Z","shell.execute_reply":"2023-10-06T13:21:25.530556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze the bottom layers (keep only the top layers for training)\nnum_layers_to_freeze = 6  \nfor param in model.bert.encoder.layer[:num_layers_to_freeze].parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-10-06T13:21:28.447385Z","iopub.execute_input":"2023-10-06T13:21:28.447763Z","iopub.status.idle":"2023-10-06T13:21:28.453163Z","shell.execute_reply.started":"2023-10-06T13:21:28.447738Z","shell.execute_reply":"2023-10-06T13:21:28.452270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving model to GPU\nmodel.to(device)","metadata":{"_uuid":"2e05b1bd-858d-4a2c-b188-987698d65bec","_cell_guid":"457ba0e5-fa88-4e1c-88ac-5c68d4f753dd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:21:30.481793Z","iopub.execute_input":"2023-10-06T13:21:30.482119Z","iopub.status.idle":"2023-10-06T13:21:36.059930Z","shell.execute_reply.started":"2023-10-06T13:21:30.482081Z","shell.execute_reply":"2023-10-06T13:21:36.058958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=15,\n    per_device_train_batch_size=batch_size_train,\n    evaluation_strategy=\"epoch\",\n    save_total_limit=2,\n    save_steps=10,\n    logging_steps=10,\n    #learning_rate=2e-5,\n)","metadata":{"_uuid":"13881759-0482-449b-950a-9d1c46e4a5c4","_cell_guid":"a510959e-9a84-45f2-beef-cad1226c927f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:21:47.033251Z","iopub.execute_input":"2023-10-06T13:21:47.033604Z","iopub.status.idle":"2023-10-06T13:21:47.044025Z","shell.execute_reply.started":"2023-10-06T13:21:47.033578Z","shell.execute_reply":"2023-10-06T13:21:47.042725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)","metadata":{"_uuid":"b6bbf653-95fa-4835-a88f-8b012814ab20","_cell_guid":"132a1474-6729-4d09-b795-cffcaf266fef","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:21:48.590710Z","iopub.execute_input":"2023-10-06T13:21:48.591710Z","iopub.status.idle":"2023-10-06T13:21:48.596259Z","shell.execute_reply.started":"2023-10-06T13:21:48.591671Z","shell.execute_reply":"2023-10-06T13:21:48.595365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = torch.nn.CrossEntropyLoss()\n\noptimizer = AdamW(\n    filter(lambda p: p.requires_grad, model.parameters()),  \n    lr=4e-5,\n    weight_decay=0.01\n)\n\n# scheduling the learning rate\nnum_warmup_steps = 0\nnum_training_steps = len(train_dataloader) * train_args.num_train_epochs\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps,\n)","metadata":{"_uuid":"5eb04ba6-ccc5-49dd-8ad0-a2966c1ed312","_cell_guid":"f6d7d5c1-7ac6-4d6b-ae1f-13fe5db93ea1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:21:52.233738Z","iopub.execute_input":"2023-10-06T13:21:52.234063Z","iopub.status.idle":"2023-10-06T13:21:52.246013Z","shell.execute_reply.started":"2023-10-06T13:21:52.234038Z","shell.execute_reply":"2023-10-06T13:21:52.245039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=train_args,\n    data_collator=data_collator,\n    train_dataset=train_dataloader,  \n    eval_dataset=val_dataloader,    \n)","metadata":{"_uuid":"654c6caa-46e6-43d2-838e-cde06da44f5d","_cell_guid":"5e412dee-ef84-44bf-8766-2f05e4229d39","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:21:54.278329Z","iopub.execute_input":"2023-10-06T13:21:54.278669Z","iopub.status.idle":"2023-10-06T13:21:54.292614Z","shell.execute_reply.started":"2023-10-06T13:21:54.278642Z","shell.execute_reply":"2023-10-06T13:21:54.291773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbest_val_accuracy = 0.0\n\n\nfor epoch in range(train_args.num_train_epochs):\n    model.train()\n    \n    train_predictions = []\n    train_labels = []\n\n\n    for batch in train_dataloader:\n        input_ids = torch.stack(batch['input_ids']).to(device)\n        attention_mask = torch.stack(batch['attention_mask']).to(device)\n        labels = torch.tensor(batch['labels']).to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n        loss = loss_fn(logits, labels)  # CrossEntropyLoss\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step()  \n\n        train_predictions.extend(logits.argmax(dim=1).cpu().numpy())\n        train_labels.extend(labels.cpu().numpy())\n\n    # validating the model\n    model.eval()\n    val_predictions = []\n    val_labels = []\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids = torch.stack(batch['input_ids']).to(device)\n            attention_mask = torch.stack(batch['attention_mask']).to(device)\n            labels = torch.tensor(batch['labels']).to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            logits = outputs.logits\n            predictions = logits.argmax(dim=1).cpu().numpy()\n\n            val_predictions.extend(predictions)\n            val_labels.extend(labels.cpu().numpy())\n\n    # Counting accuracy (though it is not the exact metric that is used in the competition)\n    train_accuracy = accuracy_score(train_labels, train_predictions)\n    val_accuracy = accuracy_score(val_labels, val_predictions)\n    print(f\"Epoch {epoch+1}/{train_args.num_train_epochs}: Train Accuracy = {train_accuracy:.4f}, Validation Accuracy = {val_accuracy:.4f}\")\n\n    # saving checkpoints\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        checkpoint_path = f\"./best_checkpoint_epoch_{epoch+1}.pt\"\n        torch.save(model.state_dict(), checkpoint_path)\n    model.train()","metadata":{"_uuid":"f94e33f5-1789-4a97-82f8-ebc6758910c4","_cell_guid":"a5863135-6320-4962-8cca-0a24bc8c8feb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:21:56.028414Z","iopub.execute_input":"2023-10-06T13:21:56.029080Z","iopub.status.idle":"2023-10-06T13:35:58.129861Z","shell.execute_reply.started":"2023-10-06T13:21:56.029049Z","shell.execute_reply":"2023-10-06T13:35:58.128795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the tuned model\nmodel.save_pretrained(\"./fine_tuned_model\")","metadata":{"_uuid":"d72a3494-c083-4648-94ce-3d637289a7d2","_cell_guid":"444f0d64-ef48-46d6-8702-c6e431ece5c1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:35:58.131814Z","iopub.execute_input":"2023-10-06T13:35:58.132491Z","iopub.status.idle":"2023-10-06T13:36:01.553070Z","shell.execute_reply.started":"2023-10-06T13:35:58.132438Z","shell.execute_reply":"2023-10-06T13:36:01.551994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest.head()","metadata":{"_uuid":"26c98430-76dd-4d84-b4cc-12f3b61f25dd","_cell_guid":"d9b16a6c-1d91-43a1-8624-ab86a9e50060","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:36:01.654396Z","iopub.execute_input":"2023-10-06T13:36:01.657727Z","iopub.status.idle":"2023-10-06T13:36:01.704598Z","shell.execute_reply.started":"2023-10-06T13:36:01.657675Z","shell.execute_reply":"2023-10-06T13:36:01.703530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the fine-tuned model\n\nmodel = BertForMultipleChoice.from_pretrained(\"./fine_tuned_model\")\n\n\n#tokenizer = AutoTokenizer.from_pretrained(model_dir)","metadata":{"_uuid":"0a2f889e-8ed9-4030-bfa1-6c5ea4520212","_cell_guid":"faf0a811-16e3-4521-b79b-dad53134934f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:36:01.709990Z","iopub.execute_input":"2023-10-06T13:36:01.710400Z","iopub.status.idle":"2023-10-06T13:36:06.319240Z","shell.execute_reply.started":"2023-10-06T13:36:01.710361Z","shell.execute_reply":"2023-10-06T13:36:06.317932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_test_data(df):\n    tokenized_data = []\n\n    for index, row in df.iterrows():\n        question = row['prompt']\n        options = {\n            'A': row['A'],\n            'B': row['B'],\n            'C': row['C'],\n            'D': row['D'],\n            'E': row['E']\n        }\n\n        input_ids_list = []\n        attention_mask_list = []\n\n        for key, option in options.items():\n            encoded_data = tokenizer(\n                question,\n                option,\n                truncation=True,\n                padding='max_length',\n                max_length=128,\n                return_tensors='pt',\n            )\n\n            input_ids_list.append(encoded_data['input_ids'])\n            attention_mask_list.append(encoded_data['attention_mask'])\n\n        tokenized_example = {\n            'input_ids': input_ids_list,\n            'attention_mask': attention_mask_list,\n        }\n\n        tokenized_data.append(tokenized_example)\n\n    tokenized_df = pd.DataFrame(tokenized_data)\n    return tokenized_df\n\ntokenized_test = preprocess_test_data(test)","metadata":{"_uuid":"c08ffcfc-1860-4c88-bf41-5b2f65b42f2c","_cell_guid":"5d4c2731-7858-4835-95c7-968a11648b37","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:36:06.320731Z","iopub.execute_input":"2023-10-06T13:36:06.321661Z","iopub.status.idle":"2023-10-06T13:36:06.807346Z","shell.execute_reply.started":"2023-10-06T13:36:06.321628Z","shell.execute_reply":"2023-10-06T13:36:06.806504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, dataframe):\n        self.data = dataframe\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        input_ids = self.data.iloc[idx]['input_ids']\n        attention_mask = self.data.iloc[idx]['attention_mask']\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n        }\n\ntest_dataset = TestDataset(tokenized_test)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size_val, shuffle=False)","metadata":{"_uuid":"141e89dd-b876-4d4c-ab92-f5b1e197e8c4","_cell_guid":"53716f75-f673-4820-9ad6-759a70d7c2d1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:36:06.808517Z","iopub.execute_input":"2023-10-06T13:36:06.809029Z","iopub.status.idle":"2023-10-06T13:36:09.491402Z","shell.execute_reply.started":"2023-10-06T13:36:06.808997Z","shell.execute_reply":"2023-10-06T13:36:09.490322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict","metadata":{"_uuid":"78c1866c-ddb3-47e3-b95c-2c95474f9d39","_cell_guid":"5944c7b1-8e94-40d2-8949-21a39164c99d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:36:09.492790Z","iopub.execute_input":"2023-10-06T13:36:09.493267Z","iopub.status.idle":"2023-10-06T13:36:09.503658Z","shell.execute_reply.started":"2023-10-06T13:36:09.493234Z","shell.execute_reply":"2023-10-06T13:36:09.502791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary to store the top-3 predictions for each id\ntest_predictions = defaultdict(list)\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        input_ids = torch.stack(batch['input_ids'])\n        attention_mask = torch.stack(batch['attention_mask'])\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        # Get the top-3 predictions for each example in the batch\n        _, top3_indices = logits.topk(3, dim=1)\n        top3_predictions = top3_indices.cpu().numpy()\n\n        # Map predictions back to answer choices (A, B, C, D, E)\n        answer_choices = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n\n        # Iterate through the batch and store top-3 predictions for each id\n        for i in range(len(batch['input_ids'])):\n            id = test['id'][len(test_predictions)]\n            batch_predictions = [answer_choices[pred] for pred in top3_predictions[i]]\n            test_predictions[id].append(\" \".join(batch_predictions))","metadata":{"_uuid":"05d49908-db39-4b61-ba1f-d8481f3160ad","_cell_guid":"6faef304-8c55-4e7a-ba2a-71ad0ee749cc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:36:09.505086Z","iopub.execute_input":"2023-10-06T13:36:09.505486Z","iopub.status.idle":"2023-10-06T13:46:45.344227Z","shell.execute_reply.started":"2023-10-06T13:36:09.505434Z","shell.execute_reply":"2023-10-06T13:46:45.343206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list of dictionaries for the final submission\nsubmission_data = [{'id': id, 'prediction': \" \".join(predictions)} for id, predictions in test_predictions.items()]","metadata":{"_uuid":"f48739b9-4793-4253-885c-667670c3c9b0","_cell_guid":"c47e67c2-b9d2-4dbb-9a63-00d508fd3014","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:46:45.345772Z","iopub.execute_input":"2023-10-06T13:46:45.346314Z","iopub.status.idle":"2023-10-06T13:46:45.350908Z","shell.execute_reply.started":"2023-10-06T13:46:45.346278Z","shell.execute_reply":"2023-10-06T13:46:45.349988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame from the list of dictionaries\nsubmission_df = pd.DataFrame(submission_data)","metadata":{"_uuid":"b738f8d0-d12d-41bb-aed0-177859d319ca","_cell_guid":"7fe95394-747a-4635-a4ea-ea6c00f7fa67","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:46:45.353477Z","iopub.execute_input":"2023-10-06T13:46:45.353839Z","iopub.status.idle":"2023-10-06T13:46:45.365984Z","shell.execute_reply.started":"2023-10-06T13:46:45.353816Z","shell.execute_reply":"2023-10-06T13:46:45.365103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"_uuid":"d8682091-8d24-4057-8999-083e2484e356","_cell_guid":"08eeb7d7-9c1c-4557-aa60-bd733e133809","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:46:45.367050Z","iopub.execute_input":"2023-10-06T13:46:45.367399Z","iopub.status.idle":"2023-10-06T13:46:45.388020Z","shell.execute_reply.started":"2023-10-06T13:46:45.367369Z","shell.execute_reply":"2023-10-06T13:46:45.387156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the DataFrame to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"_uuid":"0bccd5ec-b583-4053-942b-3989e5153b18","_cell_guid":"ded0f016-a791-4b95-bcc4-9612e0ad2ef1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-06T13:46:45.389227Z","iopub.execute_input":"2023-10-06T13:46:45.389668Z","iopub.status.idle":"2023-10-06T13:46:45.403429Z","shell.execute_reply.started":"2023-10-06T13:46:45.389636Z","shell.execute_reply":"2023-10-06T13:46:45.402645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"4ff3c641-52cd-4e1b-bdad-65d3d3be2bc7","_cell_guid":"86eb13f3-6d16-42a0-9045-7cc1d9154f20","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}